name: 'K.Actions.PSModuleValidation'
description: 'Comprehensive validation of PowerShell modules: security scans, linting, and testing with enterprise-grade reporting'
author: 'GrexyLoco'

inputs:
  test-path:
    description: 'Path to the test directory containing Pester tests. If not specified, auto-discovery will search for test files up to 5 levels deep.'
    required: false
    default: ''
  output-path:
    description: 'Path for test results XML output'
    required: false
    default: './TestResults.xml'
  validate-all-codebase:
    description: 'Whether to validate all codebase or only changed files'
    required: false
    default: 'false'
  github-token:
    description: 'GitHub token for Super-Linter'
    required: true
  pester-configuration:
    description: 'Custom Pester configuration (JSON format). If not provided, defaults will be used'
    required: false
    default: ''
  module-name:
    description: 'Name of the PowerShell module being validated (for reporting)'
    required: false
    default: 'PowerShell Module'

outputs:
  test-success:
    description: 'Whether all tests passed successfully'
    value: ${{ steps.tests.outputs.test-success }}
  has-pester-tests:
    description: 'Whether any Pester tests were found and executed'
    value: ${{ steps.tests.outputs.has-pester-tests }}
  total-tests:
    description: 'Total number of tests executed'
    value: ${{ steps.tests.outputs.total-tests }}
  passed-tests:
    description: 'Number of tests that passed'
    value: ${{ steps.tests.outputs.passed-tests }}
  failed-tests:
    description: 'Number of tests that failed'
    value: ${{ steps.tests.outputs.failed-tests }}
  skipped-tests:
    description: 'Number of tests that were skipped'
    value: ${{ steps.tests.outputs.skipped-tests }}
  test-duration:
    description: 'Total test execution duration'
    value: ${{ steps.tests.outputs.test-duration }}
  test-results-path:
    description: 'Path to the test results XML file'
    value: ${{ steps.tests.outputs.test-results-path }}
  coverage-percentage:
    description: 'Code coverage percentage'
    value: ${{ steps.tests.outputs.coverage-percentage }}

runs:
  using: 'composite'
  steps:
    - name: ðŸ›¡ï¸ Security scan - GitLeaks
      uses: zricethezav/gitleaks-action@v2.3.9
      continue-on-error: true
      id: gitleaks
      
    - name: ðŸ“ GitLeaks Security Summary
      if: always()
      shell: pwsh
      run: |
        $status = if ('${{ steps.gitleaks.outcome }}' -eq 'success') { 'âœ… Completed' } else { 'âš ï¸ Skipped (License required)' }
        $result = if ('${{ steps.gitleaks.outcome }}' -eq 'success') { 'No secrets detected' } else { 'License required for full scan' }
        $summary = @"
        ## ðŸ›¡ï¸ GitLeaks Security Scan - ${{ inputs.module-name }}
        
        **Status:** $status
        **Purpose:** Detect exposed secrets, API keys, and credentials
        **Coverage:** All files in repository
        **Engine:** GitLeaks v8.x
        **Result:** $result
        
        ### Security Patterns Checked:
        - ðŸ”‘ API Keys (AWS, Google, GitHub, etc.)
        - ðŸ” Private Keys (RSA, SSH, PGP)
        - ðŸ“§ Email addresses in code
        - ðŸŒ URLs with embedded credentials
        - ðŸ’³ Credit card numbers
        
        $(if ('${{ steps.gitleaks.outcome }}' -ne 'success') { 'ðŸ’¡ **Note:** Add GITLEAKS_LICENSE secret for full scanning capability' } else { '' })
        
        ---
        "@
        Write-Output $summary >> $env:GITHUB_STEP_SUMMARY

    - name: ðŸ›¡ï¸ Security scan - Super-Linter
      uses: github/super-linter/slim@v5
      continue-on-error: true
      id: superlinter
      env:
        DEFAULT_BRANCH: ${{ github.event.repository.default_branch || 'main' }}
        GITHUB_TOKEN: ${{ inputs.github-token }}
        VALIDATE_ALL_CODEBASE: ${{ inputs.validate-all-codebase }}
        VALIDATE_POWERSHELL: true
        VALIDATE_MARKDOWN: true
        VALIDATE_YAML: true
        VALIDATE_JSON: true
        
    - name: ðŸ“ Super-Linter Quality Summary
      if: always()
      shell: pwsh
      run: |
        $coverage = if ('${{ inputs.validate-all-codebase }}' -eq 'true') { 'All files' } else { 'Changed files only' }
        $status = if ('${{ steps.superlinter.outcome }}' -eq 'success') { 'âœ… Completed' } else { 'âš ï¸ Issues found' }
        $summary = @"
        ## ðŸ›¡ï¸ Super-Linter Code Quality Scan - ${{ inputs.module-name }}
        
        **Status:** $status
        **Coverage:** $coverage
        **Engine:** GitHub Super-Linter v5
        
        ### Quality Gates Enabled:
        - ðŸ”¹ **PowerShell** (PSScriptAnalyzer) - Code quality and best practices
        - ðŸ”¹ **JSCPD** (Copy-Paste Detection) - Code duplication analysis  
        - ðŸ”¹ **Markdown** - Documentation formatting
        - ðŸ”¹ **YAML** - Configuration file validation
        - ðŸ”¹ **JSON** - Data file validation
        
        ### Standards Applied:
        - âœ… PowerShell best practices
        - âœ… Code formatting consistency
        - âœ… Documentation standards
        - âœ… Configuration file integrity
        
        $(if ('${{ steps.superlinter.outcome }}' -ne 'success') { 'âš ï¸ **Note:** Check action logs for specific linting issues' } else { '' })
        
        ---
        "@
        Write-Output $summary >> $env:GITHUB_STEP_SUMMARY

    - name: ðŸ”§ Setup Test Environment
      shell: pwsh
      run: |
        Write-Host "ðŸ”§ Setting up test environment for ${{ inputs.module-name }}..." -ForegroundColor Cyan
        
        # Remove any existing modules to ensure clean state
        Get-Module | Where-Object { $_.Name -like "*${{ inputs.module-name }}*" -or $_.Name -like "K.*" } | Remove-Module -Force -ErrorAction SilentlyContinue
        
        # Clear module cache
        if ($env:PSModulePath) {
            $env:PSModulePath.Split([IO.Path]::PathSeparator) | ForEach-Object {
                if (Test-Path $_) {
                    Get-ChildItem -Path $_ -Directory | Where-Object { $_.Name -like "*${{ inputs.module-name }}*" } | Remove-Item -Recurse -Force -ErrorAction SilentlyContinue
                }
            }
        }
        
        # Install/Update Pester if needed
        $pesterModule = Get-Module -Name Pester -ListAvailable | Sort-Object Version -Descending | Select-Object -First 1
        if (-not $pesterModule -or $pesterModule.Version -lt [version]"5.0.0") {
            Write-Host "ðŸ“¦ Installing Pester v5..." -ForegroundColor Yellow
            Install-Module -Name Pester -Force -SkipPublisherCheck -MinimumVersion 5.0.0 -Scope CurrentUser
        }
        
        Write-Host "âœ… Test environment ready" -ForegroundColor Green

    - name: ðŸ” Discover Test Files
      id: discover
      shell: pwsh
      run: |
        Write-Host "ðŸ” Discovering test files..." -ForegroundColor Cyan
        
        $testPath = '${{ inputs.test-path }}'.Trim()
        $discoveredPaths = @()
        $testFiles = @()
        
        if ($testPath -and $testPath -ne '') {
            # Use specified test path
            Write-Host "ðŸ“‚ Using specified test path: $testPath" -ForegroundColor Yellow
            
            if (Test-Path $testPath) {
                $discoveredPaths += $testPath
                $testFiles = Get-ChildItem -Path $testPath -Filter "*.Tests.ps1" -Recurse -File
                Write-Host "âœ… Found $($testFiles.Count) test files in specified path" -ForegroundColor Green
            } else {
                Write-Host "âš ï¸ Specified test path does not exist: $testPath" -ForegroundColor Yellow
                Write-Host "ðŸ“‹ This is treated as WARNING, not ERROR (no tests to run)" -ForegroundColor Yellow
                Write-Output "test-path-exists=false" >> $env:GITHUB_OUTPUT
                Write-Output "discovered-paths=" >> $env:GITHUB_OUTPUT
                Write-Output "test-files-count=0" >> $env:GITHUB_OUTPUT
                # Continue execution - no tests is not an error condition
            }
        } else {
            # Auto-discovery mode
            Write-Host "ðŸ” Auto-discovering test files (up to 5 levels deep)..." -ForegroundColor Yellow
            
            # Common test directory patterns
            $testPatterns = @(
                "Tests", "Test", "tests", "test",
                "UnitTests", "unittests", "Pester",
                "specs", "Specs"
            )
            
            # Search for test directories
            for ($depth = 0; $depth -le 5; $depth++) {
                $searchPath = if ($depth -eq 0) { "." } else { ("*/" * $depth).TrimEnd('/') }
                
                foreach ($pattern in $testPatterns) {
                    $searchPattern = if ($depth -eq 0) { $pattern } else { "$searchPath/$pattern" }
                    $foundDirs = Get-ChildItem -Path $searchPattern -Directory -ErrorAction SilentlyContinue
                    
                    foreach ($dir in $foundDirs) {
                        if ($dir.FullName -notin $discoveredPaths) {
                            $discoveredPaths += $dir.FullName
                            Write-Host "ðŸ“ Found test directory: $($dir.FullName)" -ForegroundColor Cyan
                        }
                    }
                }
            }
            
            # Search for test files directly (for flat structures)
            for ($depth = 0; $depth -le 5; $depth++) {
                $searchPath = if ($depth -eq 0) { "." } else { ("*/" * $depth).TrimEnd('/') }
                $searchPattern = if ($depth -eq 0) { "*.Tests.ps1" } else { "$searchPath/*.Tests.ps1" }
                
                $foundFiles = Get-ChildItem -Path $searchPattern -File -ErrorAction SilentlyContinue
                foreach ($file in $foundFiles) {
                    $parentDir = $file.Directory.FullName
                    if ($parentDir -notin $discoveredPaths) {
                        $discoveredPaths += $parentDir
                        Write-Host "ðŸ“„ Found test files in: $parentDir" -ForegroundColor Cyan
                    }
                }
            }
            
            # Collect all test files from discovered paths
            foreach ($path in $discoveredPaths) {
                $files = Get-ChildItem -Path $path -Filter "*.Tests.ps1" -File -ErrorAction SilentlyContinue
                $testFiles += $files
            }
            
            Write-Host "ðŸ” Auto-discovery complete:" -ForegroundColor Green
            Write-Host "   ðŸ“ Discovered paths: $($discoveredPaths.Count)" -ForegroundColor Green
            Write-Host "   ðŸ“„ Test files found: $($testFiles.Count)" -ForegroundColor Green
        }
        
        # Set outputs
        $pathsString = $discoveredPaths -join ';'
        Write-Output "test-path-exists=true" >> $env:GITHUB_OUTPUT
        Write-Output "discovered-paths=$pathsString" >> $env:GITHUB_OUTPUT
        Write-Output "test-files-count=$($testFiles.Count)" >> $env:GITHUB_OUTPUT
        
        # Display discovered test files
        if ($testFiles.Count -gt 0) {
            Write-Host "ðŸ“‹ Discovered test files:" -ForegroundColor Green
            foreach ($file in $testFiles) {
                Write-Host "   âœ… $($file.FullName)" -ForegroundColor Gray
            }
        } else {
            Write-Host "âš ï¸ No test files (*.Tests.ps1) found" -ForegroundColor Yellow
        }

    - name: ðŸ§ª Execute Pester Tests
      id: tests
      shell: pwsh
      run: |
        Write-Host "ðŸ§ª Running Pester tests for ${{ inputs.module-name }}..." -ForegroundColor Cyan
        
        # Import Pester
        Import-Module Pester -Force
        
        # Get discovery results
        $testFilesCount = [int]'${{ steps.discover.outputs.test-files-count }}'
        $discoveredPaths = '${{ steps.discover.outputs.discovered-paths }}'.Split(';', [StringSplitOptions]::RemoveEmptyEntries)
        
        if ($testFilesCount -eq 0) {
            Write-Host "âš ï¸ No test files found - this is a WARNING, not an error" -ForegroundColor Yellow
            
            # Set outputs for no tests scenario
            Write-Output "test-success=true" >> $env:GITHUB_OUTPUT
            Write-Output "has-pester-tests=false" >> $env:GITHUB_OUTPUT
            Write-Output "total-tests=0" >> $env:GITHUB_OUTPUT  
            Write-Output "passed-tests=0" >> $env:GITHUB_OUTPUT
            Write-Output "failed-tests=0" >> $env:GITHUB_OUTPUT
            Write-Output "skipped-tests=0" >> $env:GITHUB_OUTPUT
            Write-Output "test-duration=0" >> $env:GITHUB_OUTPUT
            Write-Output "test-results-path=" >> $env:GITHUB_OUTPUT
            Write-Output "coverage-percentage=0" >> $env:GITHUB_OUTPUT
            
            Write-Host "âœ… No tests to run - continuing without error" -ForegroundColor Green
            return
        }
        
        # Prepare test configuration
        $outputPath = "${{ inputs.output-path }}"
        if (-not $outputPath -or $outputPath -eq '') {
            $outputPath = "./TestResults.xml"
        }
        
        # Create output directory if needed
        $outputDir = Split-Path $outputPath -Parent
        if ($outputDir -and (-not (Test-Path $outputDir))) {
            New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
        }
        
        # Use discovered paths or specific test files
        $testPaths = if ($discoveredPaths.Count -gt 0) { $discoveredPaths } else { @('.') }
        
        Write-Host "ðŸ“‹ Test configuration:" -ForegroundColor Cyan
        Write-Host "   ðŸ“ Test paths: $($testPaths -join ', ')" -ForegroundColor Gray
        Write-Host "   ðŸ“„ Output path: $outputPath" -ForegroundColor Gray
        Write-Host "   ðŸ“Š Test files found: $testFilesCount" -ForegroundColor Gray
        
        # Configure Pester
        $pesterConfig = if ('${{ inputs.pester-configuration }}') {
            '${{ inputs.pester-configuration }}' | ConvertFrom-Json
        } else {
            @{
                Run = @{
                    Path = $testPaths
                    PassThru = $true
                }
                Output = @{
                    Verbosity = 'Detailed'
                }
                TestResult = @{
                    Enabled = $true
                    OutputPath = $outputPath
                    OutputFormat = 'NUnitXml'
                }
                CodeCoverage = @{
                    Enabled = $true
                    OutputFormat = 'JaCoCo'
                    Path = @('*.ps1', '*.psm1')
                }
            }
        }
        
        # Run tests
        $startTime = Get-Date
        try {
            $testResults = Invoke-Pester -Configuration $pesterConfig
            $endTime = Get-Date
            $duration = ($endTime - $startTime).TotalSeconds
            
            # Calculate metrics
            $totalTests = $testResults.TotalCount
            $passedTests = $testResults.PassedCount
            $failedTests = $testResults.FailedCount
            $skippedTests = $testResults.SkippedCount
            $testSuccess = ($failedTests -eq 0)
            $coveragePercent = if ($testResults.CodeCoverage) { 
                [math]::Round($testResults.CodeCoverage.CoveragePercent, 2) 
            } else { 0 }
            
            Write-Host "ðŸ“Š Test results summary:" -ForegroundColor Cyan
            Write-Host "   ðŸ“Š Total: $totalTests" -ForegroundColor Gray
            Write-Host "   âœ… Passed: $passedTests" -ForegroundColor Green
            Write-Host "   âŒ Failed: $failedTests" -ForegroundColor $(if ($failedTests -eq 0) { 'Gray' } else { 'Red' })
            Write-Host "   â­ï¸ Skipped: $skippedTests" -ForegroundColor Gray
            Write-Host "   â±ï¸ Duration: $([math]::Round($duration, 2))s" -ForegroundColor Gray
            Write-Host "   ðŸ“ˆ Coverage: $coveragePercent%" -ForegroundColor Gray
            
        } catch {
            Write-Host "âŒ Error running tests: $($_.Exception.Message)" -ForegroundColor Red
            
            # Set failure outputs
            $totalTests = 0
            $passedTests = 0
            $failedTests = 1
            $skippedTests = 0
            $testSuccess = $false
            $duration = 0
            $coveragePercent = 0
        }
        
        # Set outputs
        Write-Output "test-success=$testSuccess" >> $env:GITHUB_OUTPUT
        Write-Output "has-pester-tests=true" >> $env:GITHUB_OUTPUT
        Write-Output "total-tests=$totalTests" >> $env:GITHUB_OUTPUT  
        Write-Output "passed-tests=$passedTests" >> $env:GITHUB_OUTPUT
        Write-Output "failed-tests=$failedTests" >> $env:GITHUB_OUTPUT
        Write-Output "skipped-tests=$skippedTests" >> $env:GITHUB_OUTPUT
        Write-Output "test-duration=$duration" >> $env:GITHUB_OUTPUT
        Write-Output "test-results-path=$outputPath" >> $env:GITHUB_OUTPUT
        Write-Output "coverage-percentage=$coveragePercent" >> $env:GITHUB_OUTPUT
        
        # Status reporting
        if ($totalTests -eq 0) {
            Write-Host "âš ï¸ No tests were executed (no test files found)" -ForegroundColor Yellow
        } elseif ($testSuccess) {
            Write-Host "âœ… All tests passed!" -ForegroundColor Green
        } else {
            Write-Host "âŒ $failedTests test(s) failed!" -ForegroundColor Red
            exit 1
        }

    - name: ðŸ“Š Generate Test Summary
      if: always()
      shell: pwsh
      run: |
        $totalTests = '${{ steps.tests.outputs.total-tests }}'
        $passedTests = '${{ steps.tests.outputs.passed-tests }}'
        $failedTests = '${{ steps.tests.outputs.failed-tests }}'
        $skippedTests = '${{ steps.tests.outputs.skipped-tests }}'
        $duration = '${{ steps.tests.outputs.test-duration }}'
        $coverage = '${{ steps.tests.outputs.coverage-percentage }}'
        $success = '${{ steps.tests.outputs.test-success }}'
        $testFilesCount = '${{ steps.discover.outputs.test-files-count }}'
        $discoveredPaths = '${{ steps.discover.outputs.discovered-paths }}'
        
        # Determine scenario
        $isNoTestsScenario = [int]$totalTests -eq 0
        
        if ($isNoTestsScenario) {
            # No tests found scenario
            $statusIcon = 'âš ï¸'
            $statusText = 'NO TESTS FOUND'
            $coverageIcon = 'ðŸ“Š'
            $discoveryInfo = if ($discoveredPaths) {
                "**Searched paths:** $($discoveredPaths -replace ';', ', ')"
            } else {
                "**Search depth:** Up to 5 levels"
            }
            
            $summary = @"
        ## ðŸ§ª Test Results - ${{ inputs.module-name }} $statusIcon
        
        ### Overview
        **Status:** $statusIcon **$statusText**
        **Test files found:** $testFilesCount
        **Action result:** âœ… **PASSED** (No tests is not an error)
        
        ### Test Discovery
        **Strategy:** $(if ('${{ inputs.test-path }}') { 'Specified path' } else { 'Auto-discovery' })
        $discoveryInfo
        **Patterns searched:** *.Tests.ps1
        
        ### Action Behavior
        - âœ… **No Error**: Missing tests are treated as warning only
        - ðŸ” **Auto-Discovery**: Searched up to 5 levels deep for test files
        - ðŸ“‹ **Common Patterns**: Tests, Test, UnitTests, Pester, specs
        - ï¿½ **Output**: \`has-pester-tests=false\` indicates no tests were found
        - ï¿½ðŸ’¡ **Recommendation**: Add Pester tests in a 'Tests' directory
        
        ---
        **Note:** This action only fails when tests exist but don't pass. No tests = Warning only! âš ï¸
        "@
        } else {
            # Tests were found and executed
            $statusIcon = if ($success -eq 'true') { 'âœ…' } else { 'âŒ' }
            $statusText = if ($success -eq 'true') { 'PASSED' } else { 'FAILED' }
            $coverageIcon = if ([double]$coverage -ge 80) { 'ðŸŸ¢' } else { if ([double]$coverage -ge 60) { 'ðŸŸ¡' } else { 'ðŸ”´' } }
            
            $summary = @"
        ## ðŸ§ª Test Results - ${{ inputs.module-name }} $statusIcon
        
        ### Overview
        **Status:** $statusIcon **$statusText**
        **Duration:** $([math]::Round([double]$duration, 2)) seconds
        **Coverage:** $coverageIcon **$coverage%**
        **Test files:** $testFilesCount
        
        ### Test Metrics
        | Metric | Count | Percentage |
        |--------|-------|------------|
        | âœ… Passed | $passedTests | $([math]::Round(([double]$passedTests / [double]$totalTests) * 100, 1))% |
        | âŒ Failed | $failedTests | $([math]::Round(([double]$failedTests / [double]$totalTests) * 100, 1))% |
        | â­ï¸ Skipped | $skippedTests | $([math]::Round(([double]$skippedTests / [double]$totalTests) * 100, 1))% |
        | ðŸ“Š **Total** | **$totalTests** | **100%** |
        
        ### Test Discovery
        **Strategy:** $(if ('${{ inputs.test-path }}') { 'Specified path' } else { 'Auto-discovery' })
        **Paths used:** $($discoveredPaths -replace ';', ', ')
        
        ### Quality Gates
        - ðŸ§ª **Test Success:** $statusIcon $(if ($success -eq 'true') { 'All tests passed' } else { "$failedTests test(s) failed" })
        - ðŸ“ˆ **Code Coverage:** $coverageIcon $coverage% $(if ([double]$coverage -ge 80) { '(Excellent)' } elseif ([double]$coverage -ge 60) { '(Good)' } else { '(Needs Improvement)' })
        - âš¡ **Performance:** $([math]::Round([double]$duration, 2))s $(if ([double]$duration -le 30) { '(Fast)' } elseif ([double]$duration -le 120) { '(Moderate)' } else { '(Slow)' })
        
        ---
        "@
        }
        
        Write-Output $summary >> $env:GITHUB_STEP_SUMMARY

    - name: ðŸ“„ Upload Test Artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ inputs.module-name }}
        path: ${{ inputs.output-path }}
        retention-days: 30

branding:
  icon: 'shield'
  color: 'blue'
