name: 'K.Actions.PSModuleValidation'
description: 'Comprehensive validation of PowerShell modules: security scans, linting, and testing with enterprise-grade reporting'
author: 'GrexyLoco'

inputs:
  test-path:
    description: 'Path to the test directory containing Pester tests. If not specified, auto-discovery will search for test files up to 5 levels deep.'
    required: false
    default: ''
  test-exclude-paths:
    description: 'Paths to exclude from auto-discovery (semicolon-separated). Default excludes test setup directories.'
    required: false
    default: 'TestSetup;test-module;.github'
  output-path:
    description: 'Path for test results XML output'
    required: false
    default: './TestResults.xml'
  validate-all-codebase:
    description: 'Whether to validate all codebase or only changed files'
    required: false
    default: 'false'
  github-token:
    description: 'GitHub token for Super-Linter'
    required: true
  pester-configuration:
    description: 'Custom Pester configuration (JSON format). If not provided, defaults will be used'
    required: false
    default: ''
  module-name:
    description: 'Name of the PowerShell module being validated (for reporting)'
    required: false
    default: 'PowerShell Module'

outputs:
  test-success:
    description: 'Whether all tests passed successfully'
    value: ${{ steps.tests.outputs.test-success }}
  has-pester-tests:
    description: 'Whether any Pester tests were found and executed'
    value: ${{ steps.tests.outputs.has-pester-tests }}
  total-tests:
    description: 'Total number of tests executed'
    value: ${{ steps.tests.outputs.total-tests }}
  passed-tests:
    description: 'Number of tests that passed'
    value: ${{ steps.tests.outputs.passed-tests }}
  failed-tests:
    description: 'Number of tests that failed'
    value: ${{ steps.tests.outputs.failed-tests }}
  skipped-tests:
    description: 'Number of tests that were skipped'
    value: ${{ steps.tests.outputs.skipped-tests }}
  test-duration:
    description: 'Total test execution duration'
    value: ${{ steps.tests.outputs.test-duration }}
  test-results-path:
    description: 'Path to the test results XML file'
    value: ${{ steps.tests.outputs.test-results-path }}
  coverage-percentage:
    description: 'Code coverage percentage'
    value: ${{ steps.tests.outputs.coverage-percentage }}

runs:
  using: 'composite'
  steps:
    - name: 🛡️ Security scan - GitLeaks
      uses: zricethezav/gitleaks-action@v2.3.9
      continue-on-error: true
      id: gitleaks
      
    - name: 📝 GitLeaks Security Summary
      if: always()
      shell: pwsh
      run: |
        $status = if ('${{ steps.gitleaks.outcome }}' -eq 'success') { '✅ Completed' } else { '⚠️ Skipped (License required)' }
        $result = if ('${{ steps.gitleaks.outcome }}' -eq 'success') { 'No secrets detected' } else { 'License required for full scan' }
        $summary = @"
        ## 🛡️ GitLeaks Security Scan - ${{ inputs.module-name }}
        
        **Status:** $status
        **Purpose:** Detect exposed secrets, API keys, and credentials
        **Coverage:** All files in repository
        **Engine:** GitLeaks v8.x
        **Result:** $result
        
        ### Security Patterns Checked:
        - 🔑 API Keys (AWS, Google, GitHub, etc.)
        - 🔐 Private Keys (RSA, SSH, PGP)
        - 📧 Email addresses in code
        - 🌐 URLs with embedded credentials
        - 💳 Credit card numbers
        
        $(if ('${{ steps.gitleaks.outcome }}' -ne 'success') { '💡 **Note:** Add GITLEAKS_LICENSE secret for full scanning capability' } else { '' })
        
        ---
        "@
        Write-Output $summary >> $env:GITHUB_STEP_SUMMARY

    - name: 🛡️ Security scan - Super-Linter
      uses: github/super-linter/slim@v5
      continue-on-error: true
      id: superlinter
      env:
        DEFAULT_BRANCH: ${{ github.event.repository.default_branch || 'main' }}
        GITHUB_TOKEN: ${{ inputs.github-token }}
        VALIDATE_ALL_CODEBASE: ${{ inputs.validate-all-codebase }}
        VALIDATE_POWERSHELL: true
        VALIDATE_MARKDOWN: true
        VALIDATE_YAML: true
        VALIDATE_JSON: true
        
    - name: 📝 Super-Linter Quality Summary
      if: always()
      shell: pwsh
      run: |
        $coverage = if ('${{ inputs.validate-all-codebase }}' -eq 'true') { 'All files' } else { 'Changed files only' }
        $status = if ('${{ steps.superlinter.outcome }}' -eq 'success') { '✅ Completed' } else { '⚠️ Issues found' }
        $summary = @"
        ## 🛡️ Super-Linter Code Quality Scan - ${{ inputs.module-name }}
        
        **Status:** $status
        **Coverage:** $coverage
        **Engine:** GitHub Super-Linter v5
        
        ### Quality Gates Enabled:
        - 🔹 **PowerShell** (PSScriptAnalyzer) - Code quality and best practices
        - 🔹 **JSCPD** (Copy-Paste Detection) - Code duplication analysis  
        - 🔹 **Markdown** - Documentation formatting
        - 🔹 **YAML** - Configuration file validation
        - 🔹 **JSON** - Data file validation
        
        ### Standards Applied:
        - ✅ PowerShell best practices
        - ✅ Code formatting consistency
        - ✅ Documentation standards
        - ✅ Configuration file integrity
        
        $(if ('${{ steps.superlinter.outcome }}' -ne 'success') { '⚠️ **Note:** Check action logs for specific linting issues' } else { '' })
        
        ---
        "@
        Write-Output $summary >> $env:GITHUB_STEP_SUMMARY

    - name: 🔍 Smart Test Discovery
      id: discover
      shell: pwsh
      run: |
        Write-Host "🔍 Attempting to load enhanced test discovery..." -ForegroundColor Cyan
        
        # Try to use PowerShell Gallery module for enhanced discovery
        $useEnhancedDiscovery = $false
        try {
            Install-Module K.PSGallery.PesterTestDiscovery -Force -Scope CurrentUser -ErrorAction Stop
            Import-Module K.PSGallery.PesterTestDiscovery -Force
            Write-Host "✅ Enhanced test discovery loaded successfully" -ForegroundColor Green
            $useEnhancedDiscovery = $true
        } catch {
            Write-Host "⚠️ Enhanced discovery unavailable, using built-in discovery" -ForegroundColor Yellow
            Write-Host "📋 Reason: $($_.Exception.Message)" -ForegroundColor Gray
        }
        
        if ($useEnhancedDiscovery) {
            # Use the enhanced K.PSGallery.PesterTestDiscovery module
            Write-Host "🚀 Using enhanced test discovery with GitHub Actions integration..." -ForegroundColor Cyan
            $result = Invoke-TestDiscovery -TestPath '${{ inputs.test-path }}' -ExcludePaths '${{ inputs.test-exclude-paths }}'.Split(';', [StringSplitOptions]::RemoveEmptyEntries) -OutputFormat 'GitHubActions' -Detailed
            
            Write-Host "📊 Enhanced discovery results:" -ForegroundColor Green
            Write-Host "   📁 Test files: $($result.TestFilesCount)" -ForegroundColor Gray
            Write-Host "   📂 Directories: $($result.TestDirectories.Count)" -ForegroundColor Gray
            Write-Host "   🎯 Patterns: $($result.PatternsUsed -join ', ')" -ForegroundColor Gray
        } else {
            # Fallback to built-in discovery logic
            Write-Host "🔍 Using built-in test discovery..." -ForegroundColor Cyan
            
            # Built-in test discovery logic
            $testPath = '${{ inputs.test-path }}'
            $excludePaths = '${{ inputs.test-exclude-paths }}'.Split(';', [StringSplitOptions]::RemoveEmptyEntries)
            
            # Determine search paths
            $searchPaths = if ($testPath -and $testPath.Trim() -ne '') {
                @($testPath)
            } else {
                # Auto-discovery: Look for Test/Tests directories
                $testDirs = Get-ChildItem -Path "." -Directory -Recurse -ErrorAction SilentlyContinue | 
                    Where-Object { $_.Name -match '^Tests?$' -and $excludePaths -notcontains $_.Name }
                
                if ($testDirs) {
                    $testDirs.FullName
                } else {
                    @('.')  # Fallback to current directory
                }
            }
            
            # Find test files
            $testFiles = @()
            foreach ($path in $searchPaths) {
                if (Test-Path $path) {
                    $files = Get-ChildItem -Path $path -Filter "*.Tests.ps1" -Recurse -ErrorAction SilentlyContinue
                    $files += Get-ChildItem -Path $path -Filter "*.Test.ps1" -Recurse -ErrorAction SilentlyContinue
                    $testFiles += $files
                }
            }
            
            # Filter out excluded paths
            $testFiles = $testFiles | Where-Object {
                $filePath = $_.FullName
                $shouldExclude = $false
                foreach ($exclude in $excludePaths) {
                    if ($filePath -like "*$exclude*") {
                        $shouldExclude = $true
                        break
                    }
                }
                -not $shouldExclude
            }
            
            $testFilesCount = $testFiles.Count
            $discoveredPaths = ($testFiles | ForEach-Object { $_.DirectoryName } | Sort-Object -Unique) -join ';'
            
            # Set GitHub Actions outputs for built-in discovery
            Write-Output "test-files-count=$testFilesCount" >> $env:GITHUB_OUTPUT
            Write-Output "discovered-paths=$discoveredPaths" >> $env:GITHUB_OUTPUT
            
            Write-Host "🔍 Built-in discovery complete - Found $testFilesCount test files" -ForegroundColor Green
            if ($testFilesCount -gt 0) {
                Write-Host "📁 Test directories: $($discoveredPaths -replace ';', ', ')" -ForegroundColor Gray
            }
        }

    - name: 🧪 Execute Pester Tests
      id: tests
      shell: pwsh
      run: |
          Write-Host "🧪 Running Pester tests for ${{ inputs.module-name }}..." -ForegroundColor Cyan
          
          # Import Pester
          Import-Module Pester -Force
          
          # Get discovery results
          $testFilesCount = [int]'${{ steps.discover.outputs.test-files-count }}'
          $discoveredPaths = '${{ steps.discover.outputs.discovered-paths }}'.Split(';', [StringSplitOptions]::RemoveEmptyEntries)
          
          if ($testFilesCount -eq 0) {
              Write-Host "⚠️ No test files found - this is a WARNING, not an error" -ForegroundColor Yellow
              
              # Set outputs for no tests scenario
              Write-Output "test-success=true" >> $env:GITHUB_OUTPUT
              Write-Output "has-pester-tests=false" >> $env:GITHUB_OUTPUT
              Write-Output "total-tests=0" >> $env:GITHUB_OUTPUT  
              Write-Output "passed-tests=0" >> $env:GITHUB_OUTPUT
              Write-Output "failed-tests=0" >> $env:GITHUB_OUTPUT
              Write-Output "skipped-tests=0" >> $env:GITHUB_OUTPUT
              Write-Output "test-duration=0" >> $env:GITHUB_OUTPUT
              Write-Output "test-results-path=" >> $env:GITHUB_OUTPUT
              Write-Output "coverage-percentage=0" >> $env:GITHUB_OUTPUT
              
              Write-Host "✅ No tests to run - continuing without error" -ForegroundColor Green
              return
          }
          
          # Prepare test configuration
          $outputPath = "${{ inputs.output-path }}"
          if (-not $outputPath -or $outputPath -eq '') {
              $outputPath = "./TestResults.xml"
          }
          
          # Create output directory if needed
          $outputDir = Split-Path $outputPath -Parent
          if ($outputDir -and (-not (Test-Path $outputDir))) {
              New-Item -ItemType Directory -Path $outputDir -Force | Out-Null
          }
          
          # Use discovered paths or specific test files
          $testPaths = if ($discoveredPaths.Count -gt 0) { $discoveredPaths } else { @('.') }
          
          Write-Host "📋 Test configuration:" -ForegroundColor Cyan
          Write-Host "   📁 Test paths: $($testPaths -join ', ')" -ForegroundColor Gray
          Write-Host "   📄 Output path: $outputPath" -ForegroundColor Gray
          Write-Host "   📊 Test files found: $testFilesCount" -ForegroundColor Gray
          
          # Configure Pester with robust error handling
          $pesterConfig = if ('${{ inputs.pester-configuration }}') {
              try {
                  '${{ inputs.pester-configuration }}' | ConvertFrom-Json
              } catch {
                  Write-Host "⚠️ Invalid Pester configuration JSON, using defaults" -ForegroundColor Yellow
                  $null
              }
          } else {
              $null
          }
          
          # Use default configuration if custom config failed or not provided
          if (-not $pesterConfig) {
              # Find PowerShell files for code coverage
              $psFiles = Get-ChildItem -Path "." -Include "*.ps1", "*.psm1" -Recurse -File -ErrorAction SilentlyContinue | Where-Object {
                  $_.FullName -notlike "*Tests*" -and $_.FullName -notlike "*.Tests.*"
              }
              
              $pesterConfig = @{
                  Run = @{
                      Path = $testPaths
                      PassThru = $true
                  }
                  Output = @{
                      Verbosity = 'Detailed'
                  }
                  TestResult = @{
                      Enabled = $true
                      OutputPath = $outputPath
                      OutputFormat = 'NUnitXml'
                  }
                  CodeCoverage = @{
                      Enabled = ($psFiles.Count -gt 0)
                      OutputFormat = 'JaCoCo'
                      Path = if ($psFiles.Count -gt 0) { $psFiles.FullName } else { @() }
                  }
              }
              
              if ($psFiles.Count -eq 0) {
                  Write-Host "⚠️ No PowerShell source files found for code coverage" -ForegroundColor Yellow
              } else {
                  Write-Host "📊 Code coverage enabled for $($psFiles.Count) PowerShell files" -ForegroundColor Green
              }
          }
          
          # Run tests
          $startTime = Get-Date
          try {
              $testResults = Invoke-Pester -Configuration $pesterConfig
              $endTime = Get-Date
              $duration = ($endTime - $startTime).TotalSeconds
              
              # Calculate metrics
              $totalTests = $testResults.TotalCount
              $passedTests = $testResults.PassedCount
              $failedTests = $testResults.FailedCount
              $skippedTests = $testResults.SkippedCount
              $testSuccess = ($failedTests -eq 0)
              $coveragePercent = if ($testResults.CodeCoverage) { 
                  [math]::Round($testResults.CodeCoverage.CoveragePercent, 2) 
              } else { 0 }
              
              Write-Host "📊 Test results summary:" -ForegroundColor Cyan
              Write-Host "   📊 Total: $totalTests" -ForegroundColor Gray
              Write-Host "   ✅ Passed: $passedTests" -ForegroundColor Green
              Write-Host "   ❌ Failed: $failedTests" -ForegroundColor $(if ($failedTests -eq 0) { 'Gray' } else { 'Red' })
              Write-Host "   ⏭️ Skipped: $skippedTests" -ForegroundColor Gray
              Write-Host "   ⏱️ Duration: $([math]::Round($duration, 2))s" -ForegroundColor Gray
              Write-Host "   📈 Coverage: $coveragePercent%" -ForegroundColor Gray
              
          } catch {
              Write-Host "❌ Error running tests: $($_.Exception.Message)" -ForegroundColor Red
              Write-Host "🔍 Error details: $($_.Exception.GetType().Name)" -ForegroundColor Yellow
              
              # Set failure outputs - tests were found but failed to execute
              $totalTests = 0
              $passedTests = 0
              $failedTests = 1  # Mark as failed due to execution error
              $skippedTests = 0
              $testSuccess = $false
              $duration = 0
              $coveragePercent = 0
              
              # has-pester-tests should be true since we found tests but they failed to run
              $hasPesterTests = $true
          }
          
          # Determine if tests were actually found and attempted
          $hasPesterTests = if ($testFilesCount -gt 0) { $true } else { $false }
          
          # Set outputs with correct values
          Write-Output "test-success=$testSuccess" >> $env:GITHUB_OUTPUT
          Write-Output "has-pester-tests=$hasPesterTests" >> $env:GITHUB_OUTPUT
          Write-Output "total-tests=$totalTests" >> $env:GITHUB_OUTPUT  
          Write-Output "passed-tests=$passedTests" >> $env:GITHUB_OUTPUT
          Write-Output "failed-tests=$failedTests" >> $env:GITHUB_OUTPUT
          Write-Output "skipped-tests=$skippedTests" >> $env:GITHUB_OUTPUT
          Write-Output "test-duration=$duration" >> $env:GITHUB_OUTPUT
          Write-Output "test-results-path=$outputPath" >> $env:GITHUB_OUTPUT
          Write-Output "coverage-percentage=$coveragePercent" >> $env:GITHUB_OUTPUT
          
          # Status reporting
          if ($totalTests -eq 0) {
              Write-Host "⚠️ No tests were executed (no test files found)" -ForegroundColor Yellow
          } elseif ($testSuccess) {
              Write-Host "✅ All tests passed!" -ForegroundColor Green
          } else {
              Write-Host "❌ $failedTests test(s) failed!" -ForegroundColor Red
              exit 1
          }

    - name: 📊 Test Results Summary
      if: always()
      shell: pwsh
      run: |
        # Get test results from previous step
        $success = '${{ steps.tests.outputs.test-success }}'
        $totalTests = '${{ steps.tests.outputs.total-tests }}'
        $passedTests = '${{ steps.tests.outputs.passed-tests }}'
        $failedTests = '${{ steps.tests.outputs.failed-tests }}'
        $skippedTests = '${{ steps.tests.outputs.skipped-tests }}'
        $duration = '${{ steps.tests.outputs.test-duration }}'
        $coverage = '${{ steps.tests.outputs.coverage-percentage }}'
        $hasPesterTests = '${{ steps.tests.outputs.has-pester-tests }}'
        $testFilesCount = '${{ steps.discover.outputs.test-files-count }}'
        $discoveredPaths = '${{ steps.discover.outputs.discovered-paths }}'
        
        if ($hasPesterTests -eq 'false') {
            # No tests were found
            $summary = @"
        ## 🧪 Test Results - ${{ inputs.module-name }} ⚠️
        
        ### No Tests Found
        **Status:** ⚠️ **NO TESTS DETECTED**
        **Strategy:** $(if ('${{ inputs.test-path }}') { 'Specified path' } else { 'Auto-discovery' })
        **Test directories discovered:** $($discoveredPaths -replace ';', ', ')
        
        ### Discovery Details
        - 🔍 **Discovery Mode**: $(if ('${{ inputs.test-path }}') { 'Explicit path: `${{ inputs.test-path }}`' } else { 'Auto-discovery (recursive search)' })
        - 📁 **Expected Structure**: Folders named 'Test' or 'Tests' containing '*.Test.ps1' or '*.Tests.ps1' files
        - 📤 **Output**: \`has-pester-tests=false\` indicates no tests were found
        - 💡 **Recommendation**: Add Pester tests in a 'Tests' directory
        
        ---
        **Note:** This action only fails when tests exist but don't pass. No tests = Warning only! ⚠️
        "@
        } else {
            # Tests were found and executed
            $statusIcon = if ($success -eq 'true') { '✅' } else { '❌' }
            $statusText = if ($success -eq 'true') { 'PASSED' } else { 'FAILED' }
            $coverageIcon = if ([double]$coverage -ge 80) { '🟢' } else { if ([double]$coverage -ge 60) { '🟡' } else { '🔴' } }
            
            $summary = @"
        ## 🧪 Test Results - ${{ inputs.module-name }} $statusIcon
        
        ### Overview
        **Status:** $statusIcon **$statusText**
        **Duration:** $([math]::Round([double]$duration, 2)) seconds
        **Coverage:** $coverageIcon **$coverage%**
        **Test files:** $testFilesCount
        
        ### Test Metrics
        | Metric | Count | Percentage |
        |--------|-------|------------|
        | ✅ Passed | $passedTests | $([math]::Round(([double]$passedTests / [double]$totalTests) * 100, 1))% |
        | ❌ Failed | $failedTests | $([math]::Round(([double]$failedTests / [double]$totalTests) * 100, 1))% |
        | ⏭️ Skipped | $skippedTests | $([math]::Round(([double]$skippedTests / [double]$totalTests) * 100, 1))% |
        | 📊 **Total** | **$totalTests** | **100%** |
        
        ### Test Discovery
        **Strategy:** $(if ('${{ inputs.test-path }}') { 'Specified path' } else { 'Auto-discovery' })
        **Paths used:** $($discoveredPaths -replace ';', ', ')
        
        ### Quality Gates
        - 🧪 **Test Success:** $statusIcon $(if ($success -eq 'true') { 'All tests passed' } else { "$failedTests test(s) failed" })
        - 📈 **Code Coverage:** $coverageIcon $coverage% $(if ([double]$coverage -ge 80) { '(Excellent)' } elseif ([double]$coverage -ge 60) { '(Good)' } else { '(Needs Improvement)' })
        - ⚡ **Performance:** $([math]::Round([double]$duration, 2))s $(if ([double]$duration -le 30) { '(Fast)' } elseif ([double]$duration -le 120) { '(Moderate)' } else { '(Slow)' })
        
        ---
        "@
        }
        
        Write-Output $summary >> $env:GITHUB_STEP_SUMMARY

    - name: 📄 Upload Test Artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ inputs.module-name }}
        path: ${{ inputs.output-path }}
        retention-days: 30

branding:
  icon: 'shield'
  color: 'blue'
